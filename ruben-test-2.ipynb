{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuck\n",
    "\n",
    "this version works with the fitness, but am not able to translate from an Individual object to just a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ruben\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy\n",
    "import array\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp\n",
    "\n",
    "import representations, fitness\n",
    "\n",
    "\n",
    "\n",
    "def getRandomIndividual(iterations=1):\n",
    "    #Possible networks to choose from:\n",
    "    '''\n",
    "    networks = [\n",
    "        [representations.make_conv2d_repr(),\n",
    "        representations.make_pool_repr()],\n",
    "\n",
    "        [representations.make_dropout_repr(),\n",
    "        representations.make_conv2d_repr()],\n",
    "\n",
    "        [representations.make_batchnorm_repr()],\n",
    "\n",
    "        [representations.make_noise_repr()]\n",
    "    ]\n",
    "\n",
    "    probabilities = [0.3, 0.3, 0.25, 0.15]\n",
    "\n",
    "    \n",
    "    out = []\n",
    "\n",
    "    \n",
    "    for x in range(0,iterations):\n",
    "        choice = numpy.random.choice(networks, p=probabilities)\n",
    "        for layer in choice:\n",
    "            out.append(layer)\n",
    "    \n",
    "    return out\n",
    "    '''\n",
    "    networks = [\n",
    "        representations.make_conv2d_pool_repr(),\n",
    "        representations.make_conv2d_dropout_repr(),\n",
    "        representations.make_batchnorm_repr(),\n",
    "        representations.make_noise_repr()\n",
    "    ]\n",
    "    probabilities = [0.3, 0.3, 0.25, 0.15]\n",
    "    \n",
    "    return numpy.random.choice(networks,p=probabilities)\n",
    "\n",
    "\n",
    "'''\n",
    "Evaluation function (should return the fitness)\n",
    "'''\n",
    "def evaluateFunc(individual):\n",
    "    return fitness.evaluate_nn(individual), #<--- IMPORTANT: add the comma ','; as it needs to return a tuple\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create attributes\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", numpy.ndarray,  fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, getRandomIndividual, n=3) #<-- Creates 3 elements\n",
    "#toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.nnelem, 3) #<-- Creates 3 elements\n",
    "#toolbox.register(\"individual\", tools.initRepeat, list, toolbox.nnelem, 3) #<-- Creates 3 elements\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# ---------------- Up till here it should work just fine\n",
    "\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluateFunc) #register the evaluation function\n",
    "#toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "#toolbox.register(\"mutate\", mutations.mutate_append_remove, prob_remove=1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "#toolbox.register(\"select\", tools.selBest)\n",
    "#deap.tools.selBest(individuals, k, fit_attr='fitness')Â¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 1.4858 - acc: 0.5420 - val_loss: 0.7175 - val_acc: 0.8100\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4615 - acc: 0.8740 - val_loss: 0.7744 - val_acc: 0.7600\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 2.2673 - acc: 0.2180 - val_loss: 1.9789 - val_acc: 0.3600\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 517us/step - loss: 1.7497 - acc: 0.4880 - val_loss: 1.5522 - val_acc: 0.5900\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 11.7493 - acc: 0.2420 - val_loss: 9.3992 - val_acc: 0.3700\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 8.6557 - acc: 0.4380 - val_loss: 8.8513 - val_acc: 0.4000\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.3977 - acc: 0.2260 - val_loss: 1.5838 - val_acc: 0.5100\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 710us/step - loss: 1.6262 - acc: 0.4220 - val_loss: 1.2776 - val_acc: 0.6200\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 1.3031 - acc: 0.5940 - val_loss: 0.6526 - val_acc: 0.7500\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4683 - acc: 0.8560 - val_loss: 0.4365 - val_acc: 0.8500\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 3.7948 - acc: 0.6140 - val_loss: 2.9720 - val_acc: 0.6800\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 2.1026 - acc: 0.8280 - val_loss: 2.3022 - val_acc: 0.7600\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.2474 - acc: 0.5920 - val_loss: 0.7904 - val_acc: 0.7800\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 943us/step - loss: 0.2460 - acc: 0.9220 - val_loss: 0.4134 - val_acc: 0.8200\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 12.6252 - acc: 0.1540 - val_loss: 11.8212 - val_acc: 0.2000\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 11.5510 - acc: 0.2500 - val_loss: 11.4329 - val_acc: 0.2500\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 12.2231 - acc: 0.1940 - val_loss: 10.0269 - val_acc: 0.3500\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 11.0757 - acc: 0.3040 - val_loss: 10.0841 - val_acc: 0.3500\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 13.0147 - acc: 0.1740 - val_loss: 12.4898 - val_acc: 0.2100\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 12.6918 - acc: 0.2100 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 1.4738 - acc: 0.5600 - val_loss: 0.7539 - val_acc: 0.7000\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.4756 - acc: 0.8600 - val_loss: 0.6356 - val_acc: 0.7900\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 2.1952 - acc: 0.2280 - val_loss: 1.7896 - val_acc: 0.4600\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 568us/step - loss: 1.5926 - acc: 0.5920 - val_loss: 1.3288 - val_acc: 0.7400\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 12.2525 - acc: 0.2240 - val_loss: 10.9704 - val_acc: 0.3000\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 943us/step - loss: 11.2094 - acc: 0.2960 - val_loss: 10.7370 - val_acc: 0.3200\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 2.4673 - acc: 0.2080 - val_loss: 1.7699 - val_acc: 0.4400\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 872us/step - loss: 1.5763 - acc: 0.4840 - val_loss: 1.3700 - val_acc: 0.5900\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 1.2197 - acc: 0.6340 - val_loss: 0.6586 - val_acc: 0.8100\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4095 - acc: 0.8780 - val_loss: 0.5789 - val_acc: 0.8100\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 2.5900 - acc: 0.6460 - val_loss: 1.7126 - val_acc: 0.7000\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.5847 - acc: 0.9240 - val_loss: 1.0793 - val_acc: 0.8200\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 1.1591 - acc: 0.6720 - val_loss: 0.5939 - val_acc: 0.8000\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.2391 - acc: 0.9180 - val_loss: 0.4582 - val_acc: 0.8200\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 12.8439 - acc: 0.1680 - val_loss: 12.3807 - val_acc: 0.2300\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 12.7800 - acc: 0.2020 - val_loss: 12.5721 - val_acc: 0.2200\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 14.1078 - acc: 0.1200 - val_loss: 14.8286 - val_acc: 0.0800\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 14.4418 - acc: 0.1040 - val_loss: 14.8286 - val_acc: 0.0800\n",
      "Succes!!\n",
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 9.5375 - acc: 0.2900 - val_loss: 7.1368 - val_acc: 0.4600\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 6.8922 - acc: 0.5140 - val_loss: 6.1954 - val_acc: 0.5400\n",
      "Succes!!\n",
      "gen\tnevals\tavg  \tstd     \tmin \tmax \n",
      "0  \t10    \t0.574\t0.260622\t0.08\t0.82\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Toolbox' object has no attribute 'mutate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1cdaedc4295b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meaSimple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalloffame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ruben\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\deap\\algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[1;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;31m# Vary the pool of individuals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0moffspring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvarAnd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# Evaluate the individuals with an invalid fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ruben\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\deap\\algorithms.py\u001b[0m in \u001b[0;36mvarAnd\u001b[1;34m(population, toolbox, cxpb, mutpb)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0moffspring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0moffspring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Toolbox' object has no attribute 'mutate'"
     ]
    }
   ],
   "source": [
    "    random.seed(1337)\n",
    "    pop = toolbox.population(n=10)\n",
    "\n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    #for ind, fit in zip(pop, fitnesses):\n",
    "    #    ind.fitness.values = fit\n",
    "\n",
    "\n",
    "    hof = tools.HallOfFame(1, similar=numpy.array_equal)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", numpy.mean)\n",
    "    stats.register(\"std\", numpy.std)\n",
    "    stats.register(\"min\", numpy.min)\n",
    "    stats.register(\"max\", numpy.max)\n",
    "    \n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=5, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    print('log: ', log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness.evaluate_nn_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import representations\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=3) #add the 'channel' dimension, in order to use Conv2D!\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "#to categorical, otherwise last dense layer expects 1 input only:\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
