{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ruben\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7576 - acc: 0.4350 - val_loss: 1.1625 - val_acc: 0.7400\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6374 - acc: 0.8600 - val_loss: 0.8619 - val_acc: 0.6800\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 15.1323 - acc: 0.0500 - val_loss: 14.0382 - val_acc: 0.1200\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 115us/step - loss: 14.3153 - acc: 0.1050 - val_loss: 13.3275 - val_acc: 0.1400\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.9919 - acc: 0.3300 - val_loss: 1.3249 - val_acc: 0.6400\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8937 - acc: 0.8150 - val_loss: 0.8546 - val_acc: 0.8200\n",
      "Error evaluating..\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.5955 - acc: 0.1600 - val_loss: 1.9485 - val_acc: 0.2400\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 550us/step - loss: 1.7529 - acc: 0.3850 - val_loss: 1.5390 - val_acc: 0.4400\n",
      "gen\tnevals\tavg  \tstd     \tmin\tmax \n",
      "0  \t0     \t0.428\t0.321646\t0  \t0.82\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.9604 - acc: 0.3500 - val_loss: 1.4745 - val_acc: 0.5200\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9629 - acc: 0.7550 - val_loss: 0.8643 - val_acc: 0.7800\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0150 - acc: 0.3900 - val_loss: 1.3738 - val_acc: 0.7400\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9548 - acc: 0.8500 - val_loss: 0.9078 - val_acc: 0.8000\n",
      "1  \t2     \t0.732\t0.146751\t0.44\t0.82\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8266 - acc: 0.4900 - val_loss: 1.2624 - val_acc: 0.6800\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8371 - acc: 0.8100 - val_loss: 0.8384 - val_acc: 0.7000\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9021 - acc: 0.4200 - val_loss: 1.2952 - val_acc: 0.5200\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8822 - acc: 0.7550 - val_loss: 0.8935 - val_acc: 0.7400\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.9591 - acc: 0.3900 - val_loss: 1.3264 - val_acc: 0.7000\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9061 - acc: 0.8250 - val_loss: 0.8184 - val_acc: 0.7600\n",
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/2\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.8704 - acc: 0.3900 - val_loss: 1.3640 - val_acc: 0.5600\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 955us/step - loss: 0.8169 - acc: 0.8300 - val_loss: 0.8130 - val_acc: 0.8000\n",
      "2  \t4     \t0.764\t0.0427083\t0.7 \t0.82\n",
      "\n",
      "----------------------------------\n",
      "gen\tnevals\tavg  \tstd      \tmin \tmax \n",
      "0  \t0     \t0.428\t0.321646 \t0   \t0.82\n",
      "1  \t2     \t0.732\t0.146751 \t0.44\t0.82\n",
      "2  \t4     \t0.764\t0.0427083\t0.7 \t0.82\n",
      "----------------------------------\n",
      "\n",
      "Best network:\n",
      "[{'type': 'noise', 'params': {'stddev': 0.2016414072580548}}\n",
      " {'type': 'noise', 'params': {'stddev': 0.695202065020174}}\n",
      " {'type': 'batchnorm', 'params': {}}\n",
      " {'type': 'conv2dpool', 'params': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 2}}]\n",
      "With a fitness of:  (0.8199999904632569,)\n",
      "\n",
      "Bad network (4th):\n",
      "[{'type': 'conv2dpool', 'params': {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 4}}\n",
      " {'type': 'conv2dpool', 'params': {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 4}}\n",
      " {'type': 'conv2dpool', 'params': {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 2}}]\n",
      "With a fitness of:  (0.0,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy\n",
    "import array\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "import representations, fitness\n",
    "\n",
    "\n",
    "#INITIAL_BLOCKS = 5 # Represents how many random layer blocks each NNet should start with\n",
    "INITIAL_BLOCKS = 5 # Random Exclusive represents how many random layer blocks each NNet should start with\n",
    "\n",
    "POPULATION = 5\n",
    "GENERATIONS = 2\n",
    "PROB_MUTATIONS = 0.0 # Probability of mutating in a new generation\n",
    "PROB_MATE = 0.8 # Probability of mating / crossover in a new generation\n",
    "NUMBER_EPOCHS = 2 #Epochs when training the network\n",
    "\n",
    "#---------------------\n",
    "\n",
    "def getRandomIndividual(iterations=1):\n",
    "    #Possible networks to choose from:\n",
    "    '''\n",
    "    networks = [\n",
    "        [representations.make_conv2d_repr(),\n",
    "        representations.make_pool_repr()],\n",
    "\n",
    "        [representations.make_dropout_repr(),\n",
    "        representations.make_conv2d_repr()],\n",
    "\n",
    "        [representations.make_batchnorm_repr()],\n",
    "\n",
    "        [representations.make_noise_repr()]\n",
    "    ]\n",
    "\n",
    "    probabilities = [0.3, 0.3, 0.25, 0.15]\n",
    "\n",
    "    \n",
    "    out = []\n",
    "\n",
    "    \n",
    "    for x in range(0,iterations):\n",
    "        choice = numpy.random.choice(networks, p=probabilities)\n",
    "        for layer in choice:\n",
    "            out.append(layer)\n",
    "    \n",
    "    return out\n",
    "    '''\n",
    "    networks = [\n",
    "        representations.make_conv2d_pool_repr(),\n",
    "        representations.make_conv2d_dropout_repr(),\n",
    "        representations.make_batchnorm_repr(),\n",
    "        representations.make_noise_repr(),\n",
    "        #representations.make_dropout_repr(),\n",
    "\n",
    "    ]\n",
    "    probabilities = [0.3, 0.3, 0.25, 0.15]\n",
    "    \n",
    "    return numpy.random.choice(networks,p=probabilities)\n",
    "\n",
    "\n",
    "'''\n",
    "Evaluation function (should return the fitness)\n",
    "'''\n",
    "def evaluateFunc(individual):\n",
    "    return fitness.evaluate_nn(individual, NUMBER_EPOCHS), #<--- IMPORTANT: add the comma ','; as it needs to return a tuple\n",
    "\n",
    "def initRepeatRandom(container, func, n):\n",
    "    \"\"\"\n",
    "    Extended toolbox.initRepeat() function to work with random initialization instead of fixed numbers.\n",
    "    \"\"\"\n",
    "    return container(func() for _ in range(numpy.random.randint(1,n)))\n",
    "\n",
    "# -------------- Init / Main stuff ----------------------\n",
    "\n",
    "# Create attributes\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", numpy.ndarray,  fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"individual\", initRepeatRandom, creator.Individual, getRandomIndividual, n=INITIAL_BLOCKS) #<-- Creates 3 elements. This random, however does not evaluate the random function each time yet\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluateFunc) #register the evaluation function\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "#toolbox.register(\"mutate\", mutations.mutate_append_remove, prob_remove=1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "#toolbox.register(\"select\", tools.selBest)\n",
    "#deap.tools.selBest(individuals, k, fit_attr='fitness')Â¶\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(1337)\n",
    "    pop = toolbox.population(n=POPULATION)\n",
    "\n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "\n",
    "    hof = tools.HallOfFame(10, similar=numpy.array_equal)\n",
    "\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", numpy.mean)\n",
    "    stats.register(\"std\", numpy.std)\n",
    "    stats.register(\"min\", numpy.min)\n",
    "    stats.register(\"max\", numpy.max)\n",
    "    \n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=PROB_MATE, mutpb=PROB_MUTATIONS, ngen=GENERATIONS, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    print(\"\\n----------------------------------\")\n",
    "    print(log)\n",
    "    print(\"----------------------------------\\n\")\n",
    "    print(\"Best network:\")\n",
    "    print(hof[0])\n",
    "    print(\"With a fitness of: \", hof[0].fitness)\n",
    "    print(\"\\nBad network (%dth):\" % 4)\n",
    "    print(hof[4])\n",
    "    print(\"With a fitness of: \", hof[4].fitness)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from representations import INSERTABLE, MUTABLE_PARAMS, default_init_nn_repr\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'activation': 'relu',\n",
       "  'filters': 64,\n",
       "  'kernel_size': 3,\n",
       "  'rate': 0.34},\n",
       " 'type': 'conv2ddropout'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indiv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Individual([{'type': 'conv2ddropout', 'params': {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'rate': 0.35}},\n",
       "            {'type': 'conv2ddropout', 'params': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'rate': 0.34}},\n",
       "            {'type': 'noise', 'params': {'stddev': 0.07034362869194766}},\n",
       "            {'type': 'conv2dpool', 'params': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 1}}],\n",
       "           dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in representations.REPR_MAKERS:\n",
    "    if indiv[1]['type'] == elem:\n",
    "        print(representations.REPR_MAKERS[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_layer(layer, verbose=False):\n",
    "    '''\n",
    "    Looks up the initializer function for a type,\n",
    "    and replaces it with a new initialization.    \n",
    "    '''\n",
    "    for elem in representations.REPR_MAKERS:\n",
    "        if layer['type'] == elem:\n",
    "            layer = representations.REPR_MAKERS[elem]()\n",
    "            if verbose:\n",
    "                print('MUTATED LAYER %s' % layer['type'])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_network(repr, mutations=1, verbose=False):\n",
    "    '''\n",
    "    Mutates a whole representation\n",
    "    '''\n",
    "    if mutations > len(repr):\n",
    "        mutations = len(repr)-1 # prevents setting higher count of mutations than length of representation\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MUTATING %d BLOCKS OF NETWORK\" % mutations)\n",
    "    \n",
    "    for layerIndex in np.random.randint(0, len(repr), mutations):\n",
    "        if verbose:\n",
    "            repr[layerIndex] = mutate_layer(repr[layerIndex], verbose=True)\n",
    "        else:\n",
    "            repr[layerIndex] = mutate_layer(repr[layerIndex])\n",
    "    return repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'activation': 'relu',\n",
       "  'filters': 32,\n",
       "  'kernel_size': 3,\n",
       "  'pool_size': 4},\n",
       " 'type': 'conv2dpool'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutate_layer(indiv[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'conv2ddropout', 'params': {'filters': 8, 'kernel_size': 3, 'activation': 'relu', 'rate': 0.39}}\n",
      " {'type': 'conv2ddropout', 'params': {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'rate': 0.24}}\n",
      " {'type': 'noise', 'params': {'stddev': 0.2762815910081766}}\n",
      " {'type': 'conv2dpool', 'params': {'filters': 8, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 2}}]\n",
      "----\n",
      "MUTATING 3 BLOCKS OF NETWORK\n",
      "MUTATED LAYER noise\n",
      "MUTATED LAYER conv2ddropout\n",
      "MUTATED LAYER conv2dpool\n",
      "[{'type': 'conv2ddropout', 'params': {'filters': 64, 'kernel_size': 3, 'activation': 'relu', 'rate': 0.29}}\n",
      " {'type': 'conv2ddropout', 'params': {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'rate': 0.24}}\n",
      " {'type': 'noise', 'params': {'stddev': 0.8524606775501399}}\n",
      " {'type': 'conv2dpool', 'params': {'filters': 32, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 2}}]\n"
     ]
    }
   ],
   "source": [
    "print(indiv)\n",
    "print('----')\n",
    "print(mutate_network(indiv, 3, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "mutations = 2\n",
    "for randindex in np.random.randint(0, len(indiv), mutations):\n",
    "    print(randindex)\n",
    "    \n",
    "# CONTINUE WITH THIS RANDOM SELECTION BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "indiv = toolbox.individual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = representations.reprs2nn(indiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433290"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = model.count_params()\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.979162528763322"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5404167494247336"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 - 0.02 * np.log(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
